// src/lmnt-provider.ts
import {
  loadApiKey,
  withUserAgentSuffix
} from "@ai-sdk/provider-utils";

// src/lmnt-speech-model.ts
import {
  combineHeaders,
  createBinaryResponseHandler,
  parseProviderOptions,
  postJsonToApi
} from "@ai-sdk/provider-utils";
import { z as z2 } from "zod/v4";

// src/lmnt-error.ts
import { z } from "zod/v4";
import { createJsonErrorResponseHandler } from "@ai-sdk/provider-utils";
var lmntErrorDataSchema = z.object({
  error: z.object({
    message: z.string(),
    code: z.number()
  })
});
var lmntFailedResponseHandler = createJsonErrorResponseHandler({
  errorSchema: lmntErrorDataSchema,
  errorToMessage: (data) => data.error.message
});

// src/lmnt-speech-model.ts
var lmntSpeechCallOptionsSchema = z2.object({
  /**
   * The model to use for speech synthesis e.g. 'aurora' or 'blizzard'.
   * @default 'aurora'
   */
  model: z2.union([z2.enum(["aurora", "blizzard"]), z2.string()]).nullish().default("aurora"),
  /**
   * The audio format of the output.
   * @default 'mp3'
   */
  format: z2.enum(["aac", "mp3", "mulaw", "raw", "wav"]).nullish().default("mp3"),
  /**
   * The sample rate of the output audio in Hz.
   * @default 24000
   */
  sampleRate: z2.union([z2.literal(8e3), z2.literal(16e3), z2.literal(24e3)]).nullish().default(24e3),
  /**
   * The speed of the speech. Range: 0.25 to 2.
   * @default 1
   */
  speed: z2.number().min(0.25).max(2).nullish().default(1),
  /**
   * A seed value for deterministic generation.
   */
  seed: z2.number().int().nullish(),
  /**
   * Whether to use a conversational style.
   * @default false
   */
  conversational: z2.boolean().nullish().default(false),
  /**
   * Maximum length of the output in seconds (up to 300).
   */
  length: z2.number().max(300).nullish(),
  /**
   * Top-p sampling parameter. Range: 0 to 1.
   * @default 1
   */
  topP: z2.number().min(0).max(1).nullish().default(1),
  /**
   * Temperature for sampling. Higher values increase randomness.
   * @default 1
   */
  temperature: z2.number().min(0).nullish().default(1)
});
var LMNTSpeechModel = class {
  constructor(modelId, config) {
    this.modelId = modelId;
    this.config = config;
    this.specificationVersion = "v2";
  }
  get provider() {
    return this.config.provider;
  }
  async getArgs({
    text,
    voice = "ava",
    outputFormat = "mp3",
    speed,
    language,
    providerOptions
  }) {
    var _a, _b, _c, _d, _e, _f, _g;
    const warnings = [];
    const lmntOptions = await parseProviderOptions({
      provider: "lmnt",
      providerOptions,
      schema: lmntSpeechCallOptionsSchema
    });
    const requestBody = {
      model: this.modelId,
      text,
      voice,
      response_format: "mp3",
      speed
    };
    if (outputFormat) {
      if (["mp3", "aac", "mulaw", "raw", "wav"].includes(outputFormat)) {
        requestBody.response_format = outputFormat;
      } else {
        warnings.push({
          type: "unsupported-setting",
          setting: "outputFormat",
          details: `Unsupported output format: ${outputFormat}. Using mp3 instead.`
        });
      }
    }
    if (lmntOptions) {
      const speechModelOptions = {
        conversational: (_a = lmntOptions.conversational) != null ? _a : void 0,
        length: (_b = lmntOptions.length) != null ? _b : void 0,
        seed: (_c = lmntOptions.seed) != null ? _c : void 0,
        speed: (_d = lmntOptions.speed) != null ? _d : void 0,
        temperature: (_e = lmntOptions.temperature) != null ? _e : void 0,
        top_p: (_f = lmntOptions.topP) != null ? _f : void 0,
        sample_rate: (_g = lmntOptions.sampleRate) != null ? _g : void 0
      };
      for (const key in speechModelOptions) {
        const value = speechModelOptions[key];
        if (value !== void 0) {
          requestBody[key] = value;
        }
      }
    }
    if (language) {
      requestBody.language = language;
    }
    return {
      requestBody,
      warnings
    };
  }
  async doGenerate(options) {
    var _a, _b, _c;
    const currentDate = (_c = (_b = (_a = this.config._internal) == null ? void 0 : _a.currentDate) == null ? void 0 : _b.call(_a)) != null ? _c : /* @__PURE__ */ new Date();
    const { requestBody, warnings } = await this.getArgs(options);
    const {
      value: audio,
      responseHeaders,
      rawValue: rawResponse
    } = await postJsonToApi({
      url: this.config.url({
        path: "/v1/ai/speech/bytes",
        modelId: this.modelId
      }),
      headers: combineHeaders(this.config.headers(), options.headers),
      body: requestBody,
      failedResponseHandler: lmntFailedResponseHandler,
      successfulResponseHandler: createBinaryResponseHandler(),
      abortSignal: options.abortSignal,
      fetch: this.config.fetch
    });
    return {
      audio,
      warnings,
      request: {
        body: JSON.stringify(requestBody)
      },
      response: {
        timestamp: currentDate,
        modelId: this.modelId,
        headers: responseHeaders,
        body: rawResponse
      }
    };
  }
};

// src/version.ts
var VERSION = true ? "1.0.15" : "0.0.0-test";

// src/lmnt-provider.ts
function createLMNT(options = {}) {
  const getHeaders = () => withUserAgentSuffix(
    {
      "x-api-key": loadApiKey({
        apiKey: options.apiKey,
        environmentVariableName: "LMNT_API_KEY",
        description: "LMNT"
      }),
      ...options.headers
    },
    `ai-sdk/lmnt/${VERSION}`
  );
  const createSpeechModel = (modelId) => new LMNTSpeechModel(modelId, {
    provider: `lmnt.speech`,
    url: ({ path }) => `https://api.lmnt.com${path}`,
    headers: getHeaders,
    fetch: options.fetch
  });
  const provider = function(modelId) {
    return {
      speech: createSpeechModel(modelId)
    };
  };
  provider.speech = createSpeechModel;
  provider.speechModel = createSpeechModel;
  return provider;
}
var lmnt = createLMNT();
export {
  VERSION,
  createLMNT,
  lmnt
};
//# sourceMappingURL=index.mjs.map