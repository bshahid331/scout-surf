"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  VERSION: () => VERSION,
  createLMNT: () => createLMNT,
  lmnt: () => lmnt
});
module.exports = __toCommonJS(src_exports);

// src/lmnt-provider.ts
var import_provider_utils3 = require("@ai-sdk/provider-utils");

// src/lmnt-speech-model.ts
var import_provider_utils2 = require("@ai-sdk/provider-utils");
var import_v42 = require("zod/v4");

// src/lmnt-error.ts
var import_v4 = require("zod/v4");
var import_provider_utils = require("@ai-sdk/provider-utils");
var lmntErrorDataSchema = import_v4.z.object({
  error: import_v4.z.object({
    message: import_v4.z.string(),
    code: import_v4.z.number()
  })
});
var lmntFailedResponseHandler = (0, import_provider_utils.createJsonErrorResponseHandler)({
  errorSchema: lmntErrorDataSchema,
  errorToMessage: (data) => data.error.message
});

// src/lmnt-speech-model.ts
var lmntSpeechCallOptionsSchema = import_v42.z.object({
  /**
   * The model to use for speech synthesis e.g. 'aurora' or 'blizzard'.
   * @default 'aurora'
   */
  model: import_v42.z.union([import_v42.z.enum(["aurora", "blizzard"]), import_v42.z.string()]).nullish().default("aurora"),
  /**
   * The audio format of the output.
   * @default 'mp3'
   */
  format: import_v42.z.enum(["aac", "mp3", "mulaw", "raw", "wav"]).nullish().default("mp3"),
  /**
   * The sample rate of the output audio in Hz.
   * @default 24000
   */
  sampleRate: import_v42.z.union([import_v42.z.literal(8e3), import_v42.z.literal(16e3), import_v42.z.literal(24e3)]).nullish().default(24e3),
  /**
   * The speed of the speech. Range: 0.25 to 2.
   * @default 1
   */
  speed: import_v42.z.number().min(0.25).max(2).nullish().default(1),
  /**
   * A seed value for deterministic generation.
   */
  seed: import_v42.z.number().int().nullish(),
  /**
   * Whether to use a conversational style.
   * @default false
   */
  conversational: import_v42.z.boolean().nullish().default(false),
  /**
   * Maximum length of the output in seconds (up to 300).
   */
  length: import_v42.z.number().max(300).nullish(),
  /**
   * Top-p sampling parameter. Range: 0 to 1.
   * @default 1
   */
  topP: import_v42.z.number().min(0).max(1).nullish().default(1),
  /**
   * Temperature for sampling. Higher values increase randomness.
   * @default 1
   */
  temperature: import_v42.z.number().min(0).nullish().default(1)
});
var LMNTSpeechModel = class {
  constructor(modelId, config) {
    this.modelId = modelId;
    this.config = config;
    this.specificationVersion = "v2";
  }
  get provider() {
    return this.config.provider;
  }
  async getArgs({
    text,
    voice = "ava",
    outputFormat = "mp3",
    speed,
    language,
    providerOptions
  }) {
    var _a, _b, _c, _d, _e, _f, _g;
    const warnings = [];
    const lmntOptions = await (0, import_provider_utils2.parseProviderOptions)({
      provider: "lmnt",
      providerOptions,
      schema: lmntSpeechCallOptionsSchema
    });
    const requestBody = {
      model: this.modelId,
      text,
      voice,
      response_format: "mp3",
      speed
    };
    if (outputFormat) {
      if (["mp3", "aac", "mulaw", "raw", "wav"].includes(outputFormat)) {
        requestBody.response_format = outputFormat;
      } else {
        warnings.push({
          type: "unsupported-setting",
          setting: "outputFormat",
          details: `Unsupported output format: ${outputFormat}. Using mp3 instead.`
        });
      }
    }
    if (lmntOptions) {
      const speechModelOptions = {
        conversational: (_a = lmntOptions.conversational) != null ? _a : void 0,
        length: (_b = lmntOptions.length) != null ? _b : void 0,
        seed: (_c = lmntOptions.seed) != null ? _c : void 0,
        speed: (_d = lmntOptions.speed) != null ? _d : void 0,
        temperature: (_e = lmntOptions.temperature) != null ? _e : void 0,
        top_p: (_f = lmntOptions.topP) != null ? _f : void 0,
        sample_rate: (_g = lmntOptions.sampleRate) != null ? _g : void 0
      };
      for (const key in speechModelOptions) {
        const value = speechModelOptions[key];
        if (value !== void 0) {
          requestBody[key] = value;
        }
      }
    }
    if (language) {
      requestBody.language = language;
    }
    return {
      requestBody,
      warnings
    };
  }
  async doGenerate(options) {
    var _a, _b, _c;
    const currentDate = (_c = (_b = (_a = this.config._internal) == null ? void 0 : _a.currentDate) == null ? void 0 : _b.call(_a)) != null ? _c : /* @__PURE__ */ new Date();
    const { requestBody, warnings } = await this.getArgs(options);
    const {
      value: audio,
      responseHeaders,
      rawValue: rawResponse
    } = await (0, import_provider_utils2.postJsonToApi)({
      url: this.config.url({
        path: "/v1/ai/speech/bytes",
        modelId: this.modelId
      }),
      headers: (0, import_provider_utils2.combineHeaders)(this.config.headers(), options.headers),
      body: requestBody,
      failedResponseHandler: lmntFailedResponseHandler,
      successfulResponseHandler: (0, import_provider_utils2.createBinaryResponseHandler)(),
      abortSignal: options.abortSignal,
      fetch: this.config.fetch
    });
    return {
      audio,
      warnings,
      request: {
        body: JSON.stringify(requestBody)
      },
      response: {
        timestamp: currentDate,
        modelId: this.modelId,
        headers: responseHeaders,
        body: rawResponse
      }
    };
  }
};

// src/version.ts
var VERSION = true ? "1.0.15" : "0.0.0-test";

// src/lmnt-provider.ts
function createLMNT(options = {}) {
  const getHeaders = () => (0, import_provider_utils3.withUserAgentSuffix)(
    {
      "x-api-key": (0, import_provider_utils3.loadApiKey)({
        apiKey: options.apiKey,
        environmentVariableName: "LMNT_API_KEY",
        description: "LMNT"
      }),
      ...options.headers
    },
    `ai-sdk/lmnt/${VERSION}`
  );
  const createSpeechModel = (modelId) => new LMNTSpeechModel(modelId, {
    provider: `lmnt.speech`,
    url: ({ path }) => `https://api.lmnt.com${path}`,
    headers: getHeaders,
    fetch: options.fetch
  });
  const provider = function(modelId) {
    return {
      speech: createSpeechModel(modelId)
    };
  };
  provider.speech = createSpeechModel;
  provider.speechModel = createSpeechModel;
  return provider;
}
var lmnt = createLMNT();
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  VERSION,
  createLMNT,
  lmnt
});
//# sourceMappingURL=index.js.map